{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "400a9fc2-877d-4eff-b0a2-f5e64bcc648c",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# HetioNet Updated Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6f0bca-a635-44b5-b7b3-bed26b21f846",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Overview\n",
    "------\n",
    "\n",
    "[HetioNet_update.ipnb](HetioNet_update.ipynb)  is a jupyter notebook that implements the code to update the G-BP relations from the original [HetioNet network](https://github.com/hetio/hetionet).\n",
    "This can be very useful for testing, training and demos.\n",
    "It provides an interactive dashboard to visualise the CPU and Disk usage whilst running the workflow.\n",
    "\n",
    "Simply run this jupyter notebook in order to construct the knowledge graph form the outputs of the processing files mentioned above. \n",
    "\n",
    "This jupyter notebook produces a `json.gzip` version of the **HetioNet Updated Network** ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "866e6634-bdd6-445b-a0d9-adec27e2e67f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import custom functions\n",
    "from tools.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "94835b0f-e918-4aad-89c7-8a57c67549ee",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import sys\n",
    "import bz2 as bz2\n",
    "import json\n",
    "import dask\n",
    "import requests\n",
    "import warnings\n",
    "\n",
    "import logging\n",
    "# import requests\n",
    "import argparse\n",
    "from pprint import pprint\n",
    "\n",
    "import dask.bag as db\n",
    "import dask.dataframe as dd\n",
    "from dask.distributed import Client\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e8d290d4-cf32-473a-b9c9-74628c587f07",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Define program global Variables\n",
    "_current_wd = os.getcwd()\n",
    "_out_path = _current_wd + '/out'\n",
    "_log_out_path = _out_path + '/running_output'\n",
    "_program_output = _out_path + '/network_outputs'\n",
    "_download_output = _out_path + '/download_outputs'\n",
    "_jsonl_path = _program_output + '/jsonl'\n",
    "\n",
    "_run_date = datetime.now().strftime(\"%Y%m%d\")\n",
    "_run_time = datetime.now().strftime(\"%H.%M\")\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c52cfad8-c695-4c43-91bc-ed8c8aa24c82",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:29:39,279 - 2703034261 - INFO: Environment set, program starts running. Current working directory is /home/llopez/git/hetnet_project\n",
      "2022-06-23 12:29:39,279 - 2703034261 - INFO: Environment set, program starts running. Current working directory is /home/llopez/git/hetnet_project\n",
      "2022-06-23 12:29:39,279 - 2703034261 - INFO: Environment set, program starts running. Current working directory is /home/llopez/git/hetnet_project\n"
     ]
    }
   ],
   "source": [
    "# Initiate logers\n",
    "logger, oh, eh = logger_outputs(_log_out_path, _run_date, _run_time)\n",
    "logger.info('Environment set, program starts running. Current working directory is {}'.format(_current_wd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "803c9b99-bce8-49a4-bce7-a9c3081340ae",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:29:43,404 - 1716776240 - INFO: Start download helionet compressed json from its origin URL: https://github.com/hetio/hetionet/raw/master/hetnet/json/hetionet-v1.0.json.bz2 using HTTP\n",
      "2022-06-23 12:29:43,404 - 1716776240 - INFO: Start download helionet compressed json from its origin URL: https://github.com/hetio/hetionet/raw/master/hetnet/json/hetionet-v1.0.json.bz2 using HTTP\n",
      "2022-06-23 12:29:43,404 - 1716776240 - INFO: Start download helionet compressed json from its origin URL: https://github.com/hetio/hetionet/raw/master/hetnet/json/hetionet-v1.0.json.bz2 using HTTP\n"
     ]
    }
   ],
   "source": [
    "# Download HetioNetJSON\n",
    "download_url = 'https://github.com/hetio/hetionet/raw/master/hetnet/json/hetionet-v1.0.json.bz2'\n",
    "logger.info('Start download helionet compressed json from its origin URL: {} using HTTP'.format(download_url))\n",
    "os.makedirs(_download_output, exist_ok=True)\n",
    "response = requests.get(download_url, stream=True)\n",
    "with open(_download_output + '/' + 'hetionet-v1.0.json.bz2', 'wb') as f:\n",
    "    for data in response:\n",
    "        f.write(data)\n",
    "# Sanity check\n",
    "while 'hetionet-v1.0.json.bz2' not in os.listdir(_download_output):\n",
    "    logger.info('Waiting for download to complete and streaming writing.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8339c112-87e9-429a-b0a4-1e2fd9c1c93d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-06-23 12:29:49,988 - 1560022088 - INFO: DOWNLOAD COMPLETE: Read json.bz2 downloaded file in streaming mode and convert it to jsonl\n",
      "2022-06-23 12:29:49,988 - 1560022088 - INFO: DOWNLOAD COMPLETE: Read json.bz2 downloaded file in streaming mode and convert it to jsonl\n",
      "2022-06-23 12:29:49,988 - 1560022088 - INFO: DOWNLOAD COMPLETE: Read json.bz2 downloaded file in streaming mode and convert it to jsonl\n"
     ]
    }
   ],
   "source": [
    "# Read json.bz2 file in streaming mode and convert it to jsonl\n",
    "logger.info('DOWNLOAD COMPLETE: Read json.bz2 downloaded file in streaming mode and convert it to jsonl')\n",
    "with bz2.open(_download_output + '/hetionet-v1.0.json.bz2', 'rb') as f:\n",
    "    json_data = json.load(f)\n",
    "    keys = [data for data in json_data]\n",
    "    for key in keys:\n",
    "        if not os.path.exists(_jsonl_path):\n",
    "            logging.debug('Creating new folder at {}'.format(_jsonl_path))\n",
    "            os.makedirs(_jsonl_path)\n",
    "        logging.debug('Generating jsonl: output_{}.jsonl.'.format(key))\n",
    "        with open(_jsonl_path + '/output_{}.jsonl'.format(key), 'w') as outfile:\n",
    "            to_write = json_data[key]\n",
    "            for element in to_write:\n",
    "                outfile.write(json.dumps(element) + \"\\n\")\n",
    "\n",
    "# Sanity Check\n",
    "logger.info('Conversion complete. Performing sanity check before starting the Extraction Pipeline')\n",
    "try:\n",
    "    len(os.listdir(_jsonl_path)) == 5\n",
    "except:\n",
    "    raise BlockingIOError('Not all jsonl files needed for downstream Dask pipeline found. Path {} contains: {}. '\n",
    "                          'Try to rerun the program'.format(_jsonl_path, os.listdir(_jsonl_path).join(',')))\n",
    "logger.info('All jsonl files needed for the downstream Dask pipeline have been generated at {}:{}.'.format(\n",
    "    _jsonl_path, str(os.listdir(_jsonl_path))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eda9c62-3b23-4cbd-9fa7-b9cf33e517f7",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Edge extraction starts\n",
    "logger.info('\"Genes\" to \"Biological Process\" Edges (G-BP) Extraction Pipeline begins.')\n",
    "# Start the Dask Client\n",
    "n_workers = 4\n",
    "threads_per_worker = 1\n",
    "memory_limit = '8GB'\n",
    "logger.info(\n",
    "    'Initiating Dask Client with the next parameters: {} workers, {} threads x worker:, memory_limit of {}.'.format(\n",
    "        n_workers, threads_per_worker, memory_limit))\n",
    "client = initiate_dask_client(n_workers, threads_per_worker, memory_limit)\n",
    "\n",
    "# Sanity check\n",
    "try:\n",
    "    client.status == 'running'\n",
    "except:\n",
    "    raise EnvironmentError('Dask client could not initiate.')\n",
    "logger.info('Dask client status is {}. INFO: {}'.format(client.status, client))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1bda23-2462-43ff-836c-adcc29fa7f15",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# Convert jsonl files into a dask bag (ONLY NODE EDGES?, Remember there are other two)\n",
    "N, E = convert_jsonl_to_bags(logger, _jsonl_path, print_example=True)\n",
    "\n",
    "# Number of Nodes of each type in the network\n",
    "logger.info('Computing the number of nodes of each type in the network')\n",
    "n_nodes = dict(N.map(lambda record: record['kind']).frequencies(sort=True).compute())\n",
    "logger.info('Number of nodes in the network: \\n----- NODE TYPES')\n",
    "pprint(n_nodes)\n",
    "print('-----')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Extract only Gene and Biological Process Nodes\n",
    "logger.info('Extracting nodes of kind:\"Gene\" and kind:\"Biological Process\" from the network')\n",
    "selected_nodes = select_gene_BP_nodes(N)\n",
    "n_selected_nodes = dict(selected_nodes.map(lambda record: record['kind']).frequencies(sort=True).compute())\n",
    "logger.info('Nodes extracted, new records contain: \\n----- SELECTED NETWORK NODE TYPES')\n",
    "pprint(n_selected_nodes)\n",
    "print('-----')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Filter to select Gene to Biological Process edges\n",
    "logger.info('Extracting G-BP Edges from the network')\n",
    "selected_edges = select_gene_BP_edges(E)\n",
    "n_selected_edges = dict(selected_edges.map(lambda record: record['kind']).frequencies(sort=True).compute())\n",
    "double = selected_edges.map(lambda record: record['target_id']).take(10), selected_edges.map(\n",
    "    lambda record: record['source_id']).take(10)\n",
    "logger.info('G-BP Edges extracted successfully! New records contain: \\n----- SELECTED EDGES')\n",
    "print('Type of edge and frequency of each type:')\n",
    "pprint(n_selected_edges)\n",
    "print('---\\nSample of 20 Edges:')\n",
    "for i in range(0, len(double[0])):\n",
    "    print(double[0][i], '------', list(n_selected_edges.keys()), '------', double[1][i])\n",
    "print('-----')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert to df\n",
    "logger.info('Converting the records of the extracted G-BP Edges into a Dask DataFrame '\n",
    "            'and save it as a jsonl output file.')\n",
    "if not os.path.exists(_program_output):\n",
    "    logging.debug('Creating new folder at {}'.format(_program_output))\n",
    "    os.makedirs(_program_output)\n",
    "# define the absolute path\n",
    "df_jsonl_name = 'G-BP_edges_formated_{}.jsonl.gzip'.format(_run_date)\n",
    "\n",
    "# Save to jsonl.gzip format\n",
    "output_absolute_path = _program_output + '/' + df_jsonl_name\n",
    "\n",
    "# execute the function\n",
    "convert_to_dd(logger, selected_edges, print_head=True, save_jsonl=True, jsonl_path=output_absolute_path)\n",
    "# Sanity Check\n",
    "try:\n",
    "    df_jsonl_name in os.listdir(_program_output)\n",
    "except:\n",
    "    FileNotFoundError('{} not found in {}. Something must have gone wrong during the export')\n",
    "logger.info('Export of {} complete at {}!'.format(df_jsonl_name, _program_output))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}